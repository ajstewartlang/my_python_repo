Reforms to improve reproducibility and quality must be coordinated across the research ecosystem: The view from the UKRN Local Network Leads

Authors

Suzanne L. K. Stewart
Corresponding Author 
School of Psychology, University of Chester, Parkgate Road, Chester CH1 4BJ, UK 
Email: s.stewart@chester.ac.uk; ORCID: https://orcid.org/0000-0003-2152-0091 

Charlotte R. Pennington
Institute of Health & Neurodevelopment, School of Psychology, College of Health & Life Sciences, Aston University, Birmingham, B4 7ET, UK
Email: c.pennington@aston.ac.uk; ORCID: https://orcid.org/0000-0002-5259-642X 

Gonçalo R. da Silva 
School of Biological Sciences, Queen’s University Belfast, 19 Chlorine Gardens, Belfast BT9 5DL, UK
Email: grosasdasilva01@qub.ac.uk, ORCID: https://orcid.org/0000-0002-1252-2709 

Nick Ballou 
Game AI Group, Queen Mary University of London, Mile End Road, London, E1 4NS, UK
Email: n.b.ballou@qmul.ac.uk; ORCID: https://orcid.org/0000-0003-4126-0696 

Jessica Butler
Centre for Health Data Science, University of Aberdeen, Aberdeen, AB25 2ZD, UK
Email: jessicabutler@abdn.ac.uk; ORCID: https://orcid.org/0000-0003-2054-3777 

Zoltan Dienes
School of Psychology, University of Sussex, Falmer, Brighton BN1 9QH, UK
Email: Z.Dienes@sussex.ac.uk; ORCID: https://orcid.org/0000-0001-7454-3161 

Caroline Jay
Department of Computer Science, University of Manchester, Oxford Road, Manchester M13 9PL, UK
Email: Caroline.Jay@manchester.ac.uk; ORCID: https://orcid.org/0000-0002-6080-1382 

Stephanie Rossit
School of Psychology, University of East Anglia, Norwich Research Park, Norwich, Norfolk NR4 7TJ, UK
Email: S.Rossit@uea.ac.uk; ORCID: https://orcid.org/0000-0001-6640-2289 

Anna Samara
Centre for Thinking & Learning, Institute for Lifecourse Development, School of Human Sciences, University of Greenwich, Old Royal Naval College, Park Row, Greenwich, London, SE10 9LS, UK 
Email: A.Samara@greenwich.ac.uk; ORCID: https://orcid.org/0000-0001-6503-5181 

UK Reproducibility Network (UKRN) Local Network Leads


Abstract

Many disciplines are facing a “reproducibility crisis”, which has precipitated much discussion about how to improve research integrity, reproducibility, and transparency. A unified effort across all sectors, levels, and stages of the research ecosystem is needed to coordinate goals and reforms that focus on open and transparent research practices. Promoting a more positive incentive culture for all ecosystem members is also paramount. In this commentary, we - the Local Network Leads of the UK Reproducibility Network - outline our response to the UK House of Commons Science and Technology Committee’s inquiry on research integrity and reproducibility. We argue that coordinated change is needed to create (1) a positive research culture, (2) a unified stance on improving research quality, (3) common foundations for open and transparent research practice, and (4) the routinisation of this practice. For each of these areas, we outline the role that individuals, institutions, funders, publishers, and Government can play in shaping the research ecosystem. Working together, these constituent members must also partner with sectoral and coordinating organisations to produce effective and long-lasting reforms that are fit-for-purpose and future-proof. These efforts will strengthen research quality and create research capable of generating far-reaching applications with a sustained impact on society. 


Key words: Science and Technology Committee; integrity; reproducibility; transparency; open research; open scholarship; research infrastructure; UK Reproducibility Network

Reforms to improve reproducibility and quality must be coordinated across the research ecosystem: The view from the UKRN Local Network Leads

Introduction
       There has been increasing scrutiny of the reproducibility and replicability of published research [1-6], two fundamental principles which cultivate the credibility, applicability, and societal impact of findings across all research fields [2]. Accordingly, in July 2021, the UK House of Commons Science and Technology Committee launched an inquiry into research integrity and reproducibility, stating that while “Government policy has focused on the overall theme of ‘Research Integrity’,...the specific issue of reproducible research has been overlooked” [7]. This commentary outlines our response to this inquiry on behalf of the UK Reproducibility Network’s (UKRN) Local Network Leads. The UKRN is a peer-led consortium which aims to ensure that the UK remains a centre for world-leading research [8]. Within its wider advocacy and training work to improve research integrity and reproducibility, the UKRN connects local researchers’ networks, formal university and research institute members, and stakeholder organisations such as funders, publishers, and policymakers [9]. 
       The research ecosystem must seize this opportunity for coordinated change. Reforms will only be effective, though, if ecosystem members identify common goals and agree on a shared path towards them. We argue that the primary goal should be to improve research quality. A critical mechanism for improving quality is reinforcing and enhancing the openness and transparency of research practice, of which reproducibility and replicability are constituent parts. Consequently, higher quality research would be capable of generating greater societal application and impact [10-12]. The difficult question for all of us in the research ecosystem is, “How do we coordinate our efforts to build a foundation of open and transparent research practice that strengthens research quality?” Here, we attempt to answer this question by outlining the coordinated actions that key research ecosystem members (individual researchers, institutions, funders, publishers, and Government) can take.
Main text
Coordinating a Positive Culture of Open and Transparent Research Practice
       Rather than an intention to mislead, research of low quality and poor integrity stems from a lack of awareness of and inadequate training in rigorous techniques and methodologies [13] and the habitual use of poor practices encouraged within a system that strongly incentivises quantity over quality [5, 14-15]. A national Government committee on research integrity should, therefore, focus on positive actions and incentives that support local and national progress towards adopting open and transparent research (OaTR) practice, coordinating with institutions to improve working cultures. Relentless pressure to publish and acquire grant funding is commonplace [14], as is the resulting detriment to researchers’ wellbeing [5, 16]. This pressure is counter-productive for two reasons. First, individuals thrive when they feel supported, recognised for effort rather than achievements, and trusted with autonomy [14]. Second, pressure to publish incentivises closed and opaque research shortcuts that increase the volume of outputs, but which, simultaneously, harm research quality [15].
       Instead, institutions should reward and encourage OaTR through their incentive structures [2, 17], for example, through their hiring, induction, probation, promotion, workload, and professional development policies and frameworks (e.g., adopting the Résumé for Researchers [18-19]). Government can, in turn, incentivise institutions by requiring evidence that reforms have been appropriately implemented. Such policy changes need clear coordination with Equality, Diversity, and Inclusion frameworks [17].
        National policies that highlight the benefits of OaTR can guide these coordinated efforts. Government should fully execute its commitment to OaTR [20], as outlined in its Research and Development Roadmap [21], with a specific national policy that incentivises positive, concrete actions and which mirrors effective reforms from other nations. For example, France [22] and the Netherlands [23] have produced systematic and concrete plans for progressing OaTR practice. Indeed, Government can set incentives for individuals, institutions, funders, and publishers to increase engagement with OaTR practice through its Higher Education policies, its funding arms, and its own institutions that conduct research and have in-house ethics and governance processes. Such cultural change will be fostered more successfully through mutually reinforced, coordinated incentive mechanisms rather than strict mandates [24].
       Similarly, funders can strategically prioritise calls for meta-research and replication projects [24]. Such initiatives would serve four key purposes: (1) demonstrating to the research community that such areas are valued and important, (2) providing new data about effective improvements to research practice to support evidence-based actions, (3) incentivising individuals and institutions to adopt OaTR practice and replication work, and (4) shifting incentive structures to reward these activities.
       The UK Government already recognises through UK Research and Innovation that open access outputs are valuable [25-26]. This positive cultural change should now be followed by a coordinated, across-the-board effort by publishers to support open access policies and publishing platforms. Funders, institutions (through subscriptions), and individuals (through targeted outlets) can all incentivise publishers to broaden and improve open access policies as well as other avenues that elevate OaTR practice such as pre-registration; Registered Reports [27-28]; and mandates for sharing data [29], materials, and code [30]. 

Coordinating a Unified Stance for Open and Transparent Research Practice
       Institutions, guided by sectoral organisations such as Universities UK [31], should coordinate and adopt common policies, guidance, and training for monitoring and improving reproducibility, openness, and quality. For example, UKRN Institutional Leads have worked with Local Network Leads to produce a series of common statements [32] for use by the sector on topics such as research transparency. This collective and collaborative sectoral approach should be informed by the voices of grassroots researchers.
       Institutions, Government, and others (e.g., Industry) should coordinate the inclusion of OaTR practice into their research ethics and governance processes. This should take a flexible approach which recognises that open and transparent practice varies by research area and, therefore, input from individual researchers and coordinating organisations such as UKRN is necessary to ensure that updated processes are sensible, executable, and compliant with other relevant frameworks (e.g., funder mandates; legal frameworks; data protection).

Coordinating the Foundations for Open and Transparent Research Practice
       Institutions, funders [33-34], and publishers should improve research infrastructure, including coordinated, cross-sector development and/or maintenance of databases, digital storage, servers, software, repositories, and various researcher-led initiatives. Collaboration with individuals and coordinating organisations (e.g., UKRN) would ensure that infrastructure is fit-for-purpose, is interoperable, and avoids duplication.
       All members of the research ecosystem should understand the role of knowledge in building a strong foundation for open and transparent research practice. Thus, institutions should recognise the diverse range of specialists who make specific contributions to research openness and transparency [35]. This includes (but is not limited to) data managers, research software engineers, statisticians, laboratory managers, technicians, and compliance officers. To sustain and integrate commitments to improving OaTR practice, institutions should establish core-funded positions for these roles with clear routes for career progression and promotion. Funders should support such roles in their schemes, and publishers should promote creditorship to recognise the contributions of these key individuals [36].
       Building a strong foundational knowledge of the practices that promote research quality is paramount for individual researchers, publishers, funders, and Government. Thus, all sectors of the research ecosystem should coordinate and mutually reinforce accessible professional development in OaTR practice (e.g., the UK Data Service’s Learning Hub [37]). Publishers should support or provide training and infrastructure [38] related to the publishing of outputs, including data management, licensing, and digital object identifiers. Similarly, funders should provide accessible training on OaTR practices that they require or encourage. This should be systematically reviewed and updated to reflect ongoing developments. Individual researchers should also be supported and incentivised by all others in the research ecosystem to engage in continuous professional development in OaTR practice, including a focus on the digital skills and infrastructure that facilitate such practice [35]. Individuals must take responsibility to ensure their knowledge and skills remain current. However, this is conditional upon broader cultural changes, including institutions promoting and providing the necessary time for continuous professional development of research skills for individuals at all career stages, in addition to employing specialists. 
       In turn, individuals have a responsibility to integrate OaTR practice into their teaching and training of students as well as junior researchers whom they manage (see the Framework for Open & Reproducible Research Training [39]). Institutions share this responsibility and can support the longevity of OaTR mentoring by coordinating training, positive incentive structures, infrastructure, and policies for workload and promotion.
       
Coordinating the routinisation of open and transparent research practice
       A coordinated effort will ensure that OaTR practice becomes routine. All members of the research ecosystem can lead particular actions, while reinforcing others, to embed openness and transparency into the everyday practice of research [2]. 
       Individuals must integrate OaTR practice from the beginning of the research process, including in following relevant ethics and governance processes and in applying for and securing research funding. Individuals should be encouraged to use research infrastructure (e.g., software) and publishing routes (e.g., Registered Reports) that support open and transparent practice throughout the research workflow. 
       Funders should require the inclusion of planned OaTR practices in funding applications. Applicants should demonstrate whether and how they will share (for example) research data, original materials and protocols, software and code, research workflows, and pre- and post-publication outputs. Depending on career stage, applicants can also be asked to demonstrate a track record of verifiable OaTR practices or professional development plans to achieve this. Additionally, funders should require confirmation that OaTR practices have been followed in funded projects (e.g., in final reports or via Researchfish [40]). Tracking and pooling locations of shared data and other intermediate outputs would allow funders to build searchable databases of available products/outputs and resources that can efficiently support future research and the development of new tools and infrastructure. This would be an advancement on current requirements to simply share data and provide accessible outputs because documented, curated open data and outputs would also become part of the research infrastructure (e.g., the UK Data Service).
       Publishers should publish rigorous replication studies [24] alongside tutorials on research processes that can help individuals, institutions, and others improve their own work [41]. As other actions to expand the adoption of OaTR practice take hold, interest in such outputs would continue to increase; hence, for-profit publishers would be implicitly incentivised by changes in supply-and-demand. Furthermore, digital word-limit-free submission formats that promote full and detailed disclosure of methodology, analytical decisions, and pilot work would encourage researchers to fully communicate essential information for reproducibility and transparency, strengthening research quality. Moreover, editorial policies that centre openness and transparency, including systematically checking for compliance with open and transparent practices, should be developed [42]. If sharing data is required, mandated compliance checks can ensure that data are openly accessible both before and after publication (see American Journal of Political Science [43]). Such checks can include statistical and analysis code reviews as appropriate [42]. Another area is systematically basing the review and selection of outputs on methodological rigour, openness, and transparency (as indicators of quality) rather than the novelty or nature of findings.
       Government, publishers, funders, institutions, and individuals should recognise the value of distributed laboratory networks and collaborative team science in relevant disciplines as models of OaTR practice [44-45]. Such large-scale collaborations have huge and untapped potential for producing impactful, reproducible, and reliable research findings, and for effectively pooling resources to minimise research waste [45]. Government and funders should incentivise such work through financial support.

Outlook
       As active researchers, we recognise the challenges and the far-reaching opportunities associated with committing to OaTR practice in the context of broader cultural changes. The burden of such changes must not rest primarily on individual researchers. Researchers’ behaviours are a response to the structure and incentives of the ecosystem in which they work; thus, it is imperative that other stakeholders such as institutions, funders, publishers, and Government work with and for individuals [46]. To do so, all research ecosystem members must progress concrete actions, such as those that we suggest here, or risk perpetuating a cycle of discussion where little changes and research quality stagnates or deteriorates [47]. This approach should be collaborative, taking advantage of the interconnected nature of the UK Higher Education system and the existence of coordinating organisations such as UKRN.



List of abbreviations
UKRN: UK Reproducibility Network
OaTR: open and transparent research

Declarations

Ethics approval and consent to participate: Not applicable. 
Consent for publication: Not applicable. 
Availability of data and materials: This manuscript is associated with a response from the UKRN Local Network Leads to the House of Commons Science and Technology Committee Inquiry on Reproducibility and Research Integrity.
Competing interests: The authors are Local Network Leads of the UK Reproducibility Network (UKRN): www.ukrn.org. 
Funding: None.
Authors' contributions: SLKS and CRP were primarily responsible for drafting the work, with SLKS having primary oversight. All other authors have made a substantial contribution to the conception, writing and/or revision of this work. All authors have approved the final submitted version and have agreed both to be personally accountable for the author's own contributions and to ensure that questions related to the accuracy or integrity of any part of the work, even ones in which the author was not personally involved, are appropriately investigated, resolved, and the resolution documented in the literature. 
Acknowledgements: We would like to thank Marcus Munafò for his feedback on this commentary. 



References

1. Dienlin T, Johannes N, Bowman ND, Masur PK, Engesser S, Kümpel AS, et al. An agenda for open science in communication. J Commun. 2020;71:1-26; doi:10.1093/joc/jqz052. 

2. Munafò MR, Nosek BA, Bishop DVM, Button KS, Chambers CD, Percie du Sert N, et al. A manifesto for reproducible science. Nat Hum Behav. 2017;1:0021; doi:10.1038/s41562-016-0021 

3. Niven DJ, McCormick TJ, Straus SE, Hemmelgarn BR, Jeffs L, Barnes TRM, Stelfox HT. Reproducibility of clinical research in critical care: A scoping review. BMC Med. 2018;16:26; doi:10.1186/s12916-018-1018-6. 

4. Open Science Collaboration. Estimating the reproducibility of psychological science. Science. 2015;349:6251; doi:10.1126/science.aac4716. 

5. Metcalfe J, Wheat K, Munafò M, Parry J. Research integrity: A landscape study. Vitae. 2020. https://www.vitae.ac.uk/vitae-publications/reports/research-integrity-a-landscape-study. Accessed 14 Oct 2021.

6. Errington TM, Mathur M, Soderberg CK, Denis A, Perfito N, Iorns E, Nosek BA. Investigating the replicability of preclinical cancer biology. eLife 2021;10:e71601; doi:10.7554/eLife.71601

7. House of Commons Science and Technology Committee. Reproducibility and research integrity inquiry. https://committees.parliament.uk/work/1433/reproducibility-and-research-integrity/. Accessed 14 Oct 2021.

8. UK Reproducibility Network. The UK Reproducibility Network (UKRN). https://www.ukrn.org/. Accessed 14 Oct 2021.

9. UK Reproducibility Network Steering Committee. From grassroots to global: A blueprint for building a reproducibility network. PLoS Biol. 2021;19(11):e3001461; doi:10.1371/journal.pbio.3001461

10. Belcher BM, Rasmussen, KE, Kemshaw MR, Zornes DA. Defining and assessing research quality in a transdisciplinary context. Res. Eval. 2016;25:1-17; doi:10.1093/reseval/rvv025

11. Colavizza G, Hrynaszkiewicz I, Staden I, Whitaker K, McGillivray B. The citation advantage of linking publications to research data. PLoS ONE. 2020;15:e0230416. doi:10.1371/journal.pone.0230416.

12. Stern N. Building on success and learning from experience: An independent review of the Research Excellence Framework. 2016. https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/541338/ind-16-9-ref-stern-review.pdf. Accessed 18 Jan 2022.

13. Colling LJ, Sz?cs D. Statistical inference and the replication crisis. Rev. Phil. Psych. 2021;12:121-147; doi:10.1007/s13164-018-0421-4

14. Frith U. Fast lane to slow science. Trends Cogn. Sci. 2020;24:1-2; doi:10.1016/j.tics.2019.10.007

15. Smaldino PE, McElreath R. The natural selection of bad science. R. Soc. Open Sci. 2016;3:160384; doi:10.1098/rsos160384

16. Wellcome Trust. What researchers think about the culture they work in. 2020. https://wellcome.org/sites/default/files/what-researchers-think-about-the-culture-they-work-in.pdf. Accessed 14 Oct 2021.

17. Gottlieb G, Smith S, Cole J, Clarke A. Realising our potential: Backing talent and strengthening UK research culture and environment. 2021. https://russellgroup.ac.uk/media/5925/realising-our-potential-report_4-compressed.pdf. Accessed 18 Jan 2022.

18. The Royal Society. Résumé for Researchers. https://royalsociety.org/topics-policy/projects/research-culture/tools-for-support/resume-for-researchers/. Accessed 14 Oct 2021.

19. Gottlieb G, Smith S, Cole J, Clarke A. Research culture and environment toolkit. 2021. https://russellgroup.ac.uk/media/5924/rce-toolkit-final-compressed.pdf. Accessed 18 Jan 2022.

20. HM Government. R&D People and Culture Strategy. 2021. https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1004685/r_d-people-culture-strategy.pdf. Accessed 18 Jan 2022.

21. HM Government. UK Research and Development Roadmap. 2020. https://www.gov.uk/government/publications/uk-research-and-development-roadmap. Accessed 14 Oct 2021.

22. Ministère de L’Enseignement Supérieur, de la Recherche et de L’Innovation. Second national plan for open science. 2021. https://www.ouvrirlascience.fr/second-national-plan-for-open-science/. Accessed 14 Oct 2021.

23. VSNU, KNAW, & NWO. Strategy Evaluation Protocol. 2020. https://www.nwo.nl/sites/nwo/files/documents/SEP_2021-2027.pdf. Accessed 14 Oct 2021.

24. Vachon B, Curran JA, Karunananthan S, Brehaut J, Graham ID, Moher D, et al. Changing research culture toward more use of replication research: A narrative review of barriers and strategies. J. Clin. Epidemiol. 2021;129:21-30; doi:10.1016/j.jclinepi.2020.09.027

25. UK Research and Innovation. UKRI Open Access Policy. 2021. https://www.ukri.org/wp-content/uploads/2021/08/UKRI-201221-UKRIOpenAccessPolicy-3.pdf. Accessed 18 Jan 2022.

26. UK Research and Innovation. UKRI Open Access Policy – explanation of policy changes. 2021. https://www.ukri.org/wp-content/uploads/2021/08/UKRI-180821-UKRIOpenAccessPolicyExplanationOfChanges-2.pdf. Accessed 18 Jan 2022.

27. Stewart SLK, Mark Rinke E, McGarrigle R, Lynott D, Lunny C, Lautarescu A, et al. Pre-registration and registered reports: a primer from UKRN. 2020; doi:10.31219/osf.io/8v2n7

28. Chambers CD, Tzavella L. The past, present and future of Registered Reports. Nat. Hum. Behav. 2021; doi:10.1086/694005

29. Towse J, Rumsey S, Owen N, Langord P, Jaquiery M, Bolibaugh C. Data sharing: a primer from UKRN. 2020; doi:10.31219/osf.io/wp4zu

30. Turner A, Topor M, Stewart A, Owen N, Kenny AR, Jones A, Ellis D. Open code and software: A primer from UKRN. 2020; doi:10.31219/osf.io/qw9ck.

31. Universities UK. Research concordats and agreements review. 2021. https://www.universitiesuk.ac.uk/topics/research-and-innovation/research-concordats-and-agreements. Accessed 14 Oct 2021. 

32. UK Reproducibility Network. Common statements. https://www.ukrn.org/common-statements/. Accessed 14 Oct 2021.

33. NIHR Open Research. https://openresearch.nihr.ac.uk/. Accessed 18 Jan 2022.

34. Wellcome Open Research. https://wellcomeopenresearch.org/. Accessed 18 Jan 2022.

35. Vitae. The concordat to support the career development of researchers. 2019. https://www.vitae.ac.uk/policy/concordat/full. Accessed 18 Jan 2022. 

36. McNutt MK, Bradford M, Drazen JM, Hanson B, Howard B, Hall Jamison K, et al. Transparency in authors’ contributions and responsibilities to promote integrity in scientific publication. PNAS. 2018;115:2557-2560. doi:10.1073/pnas.1715374115

37. UK Data Service. Learning Hub. https://ukdataservice.ac.uk/learning-hub/. Accessed 14 Oct 2021. 

38. Wiley. Open research. https://authorservices.wiley.com/open-research/index.html. Accessed 18 Jan 2022.

39. Framework for Open and Reproducible Research Training (FORRT). Framework for Open and Reproducible Research Training. https://forrt.org/. Accessed 14 Oct 2021.

40. Researchfish. Researchfish by interfolio. https://researchfish.com/. Accessed 24 Sep 2021. 

41. Simons DJ. Introducing Advances in Methods and Practices in Psychological Science. AMPPS. 2018;1:3-6. doi:10.1177%2F2515245918757424 

42. Nosek BA, Alter G, Banks GC, Borsboom D, Bowman SD, Brecker SJ et al. Promoting an open research culture. Science. 2015;348:1422-1425. doi:10.1126/science.aab2374

43. American Journal of Political Science. AJPS Verification Policy. https://ajps.org/ajps-verification-policy/. Accessed 24 Sep 2021.

44. Many Primates. Altschul DM, Beran MJ, Bohn M, Call J, DeTroy S, Duguid SJ, et al. Establishing an infrastructure for collaboration in primate cognition research. PLoS One. 2019;14:e0223675; doi:10.1371/journal.pone.0223675 

45. Moshontz H, Campbell L, Ebersole CR, IJzerman H, Urry HL, Forscher PS, et al. The Psychological Science Accelerator: Advancing psychology through a distributed collaborative network. AMPPS. 2018;1:501-515; doi:10.1177%2F2515245918797607

46. The Royal Society. Research culture: Embedding inclusive excellence. 2018. https://royalsociety.org/-/media/policy/Publications/2018/research-culture-workshop-report.pdf. Accessed 18 Jan 2022.

47. The Royal Society. Research culture: Changing expectations. 2019. https://royalsociety.org/-/media/policy/projects/changing-expectations/changing-expectations-conference-report.pdf. Accessed 18 Jan 2022.
2


